# ğŸš€ Rafcetario - CI/CD DevOps Project

**Rafcetario** es una aplicaciÃ³n fullstack de recetas, desarrollada con **React (frontend)** y **FastAPI (backend)**. Este repositorio documenta la infraestructura DevOps construida desde cero para automatizar todo el ciclo de vida de la app: testing, construcciÃ³n, despliegue, monitoreo y rollback, utilizando herramientas modernas como **GitHub Actions, Docker, Kubernetes, AWS y Terraform**.

---

## âš™ï¸ AutomatizaciÃ³n CI/CD

### âœ… 1. Testing & Linting

Workflow que ejecuta tests y linters tanto para frontend como backend, en cada `push` o `pull request` a `main`.  
Usa **SQLite** como base de datos temporal para evitar dependencias externas durante el testing.

### ğŸ³ 2. Backend: Docker + AWS ECR

ConstrucciÃ³n automÃ¡tica de una imagen Docker del backend y subida a **AWS ECR**, solo si el workflow de testing fue exitoso.  
Se etiquetan dos versiones: el SHA del commit y `latest`.

### ğŸŒ 3. Frontend: Build + AWS S3

El frontend (estÃ¡tico) se compila y despliega automÃ¡ticamente en un bucket de **AWS S3**, tambiÃ©n condicionado al Ã©xito del testing.  
Permite servir la web pÃºblica desde un origen optimizado y econÃ³mico.

---

## â˜ï¸ Infraestructura en la nube

### ğŸ” Base de datos en AWS RDS

La base de datos MySQL fue migrada desde Railway a **AWS RDS**, dentro de una VPC personalizada, optimizando seguridad, latencia y costos.

### ğŸ“¦ Terraform

Automatiza la infraestructura completa:
- CreaciÃ³n del clÃºster EKS.
- Node group en EC2.
- InstalaciÃ³n del AWS Load Balancer Controller.
- ImportaciÃ³n de la VPC existente (de la base de datos).
- DefiniciÃ³n de Security Groups optimizados y reutilizables.

### ğŸ§¬ Kubernetes

- **Secrets:** contiene variables sensibles como la URL de la base de datos y claves de AWS.
- **Namespace:** agrupa todos los recursos bajo `rafcetario`.
- **Deployment:** despliega la imagen del backend desde ECR.
- **Service:** expone el backend internamente vÃ­a `NodePort`.
- **Ingress (ALB):** habilita acceso pÃºblico a la API del backend mediante un Application Load Balancer administrado por Kubernetes.

---

## ğŸ› ï¸ Scripts

### `deploy.sh`
- Aplica la infraestructura con Terraform.
- Aplica los manifiestos de Kubernetes.
- Obtiene la URL pÃºblica del backend desde el Ingress.
- Prueba conectividad con `curl`.
- Actualiza dinÃ¡micamente `config.js` del frontend para usar la nueva URL.

### `destroy.sh`
- Elimina manifiestos de Kubernetes.
- Espera que AWS libere los recursos (como el ALB).
- Ejecuta `terraform destroy` limpiamente.

---

## âš ï¸ Retos y soluciones reales

- **Testing sin acceso a la BD:** solucionado utilizando SQLite durante los tests de CI.

- **Problemas con etiqueta `latest`:** se corrigiÃ³ asegurando que el tag `latest` se subiera explÃ­citamente a ECR.

- **Costos inesperados por EC2:** inicialmente se pensÃ³ en tener instancias EC2 separadas para backend y frontend, pero esto era innecesariamente costoso. Se intentÃ³ migrar el frontend a Fargate, pero el ahorro era mÃ­nimo. Finalmente se optÃ³ por servir el frontend desde S3, aprovechando que es estÃ¡tico. Es la soluciÃ³n mÃ¡s barata, sencilla y eficiente.

- **Limitaciones de Fargate para backend pÃºblico:** al mover el frontend a S3, el backend ya no podÃ­a comunicarse internamente con el frontend. Como Fargate no permite fÃ¡cilmente exposiciÃ³n pÃºblica sin EC2, se decidiÃ³ mantener el backend en nodos EC2 para exponerlo mediante un ALB.

- **Conectividad entre BD y backend:** inicialmente, la base de datos y el backend estaban en VPC distintas, lo que dificultaba la gestiÃ³n de reglas de acceso. Se resolviÃ³ alojando ambos en la misma VPC (la de la base de datos), simplificando la configuraciÃ³n de seguridad y mejorando el rendimiento.

- **Problemas con el ALB y los Security Groups:** al automatizar el despliegue del ALB, surgÃ­an problemas de conectividad porque el Security Group (SG) del ALB cambiaba en cada despliegue, y el SG del clÃºster no lo permitÃ­a.  
  - Se solucionÃ³ automatizando la creaciÃ³n y referencia de ambos SG desde Terraform.
  - El SG del clÃºster ahora acepta trÃ¡fico entrante desde el SG del ALB.
  - El SG del ALB se parametriza mediante variables reutilizables, asegurando una correcta exposiciÃ³n pÃºblica y evitando errores de conectividad.

---

## ğŸ§  Lecciones aprendidas

- Optimizar costos en la nube implica mÃºltiples pruebas y decisiones.
- Automatizar ALBs en Kubernetes requiere una buena comprensiÃ³n de los SGs y sus dependencias.
- No todo debe correr en EC2: saber cuÃ¡ndo usar S3, Fargate u otras soluciones puede marcar una gran diferencia.
- Documentar errores y soluciones en tiempo real acelera el desarrollo y permite aprender mÃ¡s profundamente.

---

Â¿Quieres saber mÃ¡s? Â¡Revisa los workflows YAML, manifiestos de Kubernetes y archivos Terraform en este repositorio!

---

ğŸ‘¨ğŸ»â€ğŸ’» Hecho por Rafa Casariego.
ğŸ“§ rafacasariego@gmail.com
